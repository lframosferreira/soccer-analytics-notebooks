{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [CDAF] Atividade 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Nome e matrícula\n",
    "Nome: Luís Felipe Ramos Ferreira\n",
    "Matrícula: 2019022553"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Objetivos\n",
    "- Nessa atividade, estou entregando a pipeline inteira do VAEP implementada para os dados do Wyscout das Top 5 ligas.\n",
    "- Para cada subtítulo abaixo, vocês devem explicar o que foi feito e à qual seção/subseção/equação do paper \"Actions Speak Louder than Goals: Valuing Actions by Estimating Probabilities\" ela corresponde. Justifique suas respostas.\n",
    "- Além disso, após algumas partes do código haverão perguntas que vocês devem responder, possivelmente explorando minimamente o que já está pronto.\n",
    "- Por fim, vocês devem montar um diagrama do fluxo de funções/tarefas de toda a pipeline do VAEP abaixo. Esse diagrama deve ser enviado como arquivo na submissão do Moodle, para além deste notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Referências\n",
    "- [1] https://tomdecroos.github.io/reports/kdd19_tomd.pdf\n",
    "- [2] https://socceraction.readthedocs.io/en/latest/api/vaep.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_matches(path):\n",
    "    matches = pd.read_json(path_or_buf=path)\n",
    "    # as informações dos times de cada partida estão em um dicionário dentro da coluna 'teamsData', então vamos separar essas informações\n",
    "    team_matches = []\n",
    "    for i in range(len(matches)):\n",
    "        match = pd.DataFrame(matches.loc[i, 'teamsData']).T\n",
    "        match['matchId'] = matches.loc[i, 'wyId']\n",
    "        team_matches.append(match)\n",
    "    team_matches = pd.concat(team_matches).reset_index(drop=True)\n",
    "\n",
    "    return team_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_players(path):\n",
    "    players = pd.read_json(path_or_buf=path)\n",
    "    players['player_name'] = players['firstName'] + ' ' + players['lastName']\n",
    "    players = players[['wyId', 'player_name']].rename(columns={'wyId': 'player_id'})\n",
    "\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_events(path):\n",
    "    events = pd.read_json(path_or_buf=path)\n",
    "    # pré processamento em colunas da tabela de eventos para facilitar a conversão p/ SPADL\n",
    "    events = events.rename(columns={\n",
    "        'id': 'event_id',\n",
    "        'eventId': 'type_id',\n",
    "        'subEventId': 'subtype_id',\n",
    "        'teamId': 'team_id',\n",
    "        'playerId': 'player_id',\n",
    "        'matchId': 'game_id'\n",
    "    })\n",
    "    events['milliseconds'] = events['eventSec'] * 1000\n",
    "    events['period_id'] = events['matchPeriod'].replace({'1H': 1, '2H': 2})\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_minutes_played_per_game(path):\n",
    "    minutes = pd.read_json(path_or_buf=path)\n",
    "    minutes = minutes.rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'matchId': 'game_id',\n",
    "        'teamId': 'team_id',\n",
    "        'minutesPlayed': 'minutes_played'\n",
    "    })\n",
    "    minutes = minutes.drop(['shortName', 'teamName', 'red_card'], axis=1)\n",
    "\n",
    "    return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File C:\\Users\\Galo\\Hugo_Personal\\Data\\Wyscout_Top_5\\matches\\matches_England.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m league \u001b[39min\u001b[39;00m leagues:\n\u001b[1;32m      6\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGalo\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mHugo_Personal\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWyscout_Top_5\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmatches\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmatches_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(league)\n\u001b[0;32m----> 7\u001b[0m     matches[league] \u001b[39m=\u001b[39m load_matches(path)\n\u001b[1;32m      8\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGalo\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mHugo_Personal\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWyscout_Top_5\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mevents\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mevents_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(league)\n\u001b[1;32m      9\u001b[0m     events[league] \u001b[39m=\u001b[39m load_events(path)\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m, in \u001b[0;36mload_matches\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_matches\u001b[39m(path):\n\u001b[0;32m----> 2\u001b[0m     matches \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(path_or_buf\u001b[39m=\u001b[39mpath)\n\u001b[1;32m      3\u001b[0m     \u001b[39m# as informações dos times de cada partida estão em um dicionário dentro da coluna 'teamsData', então vamos separar essas informações\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     team_matches \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/futebol/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/futebol/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/futebol/lib/python3.11/site-packages/pandas/io/json/_json.py:733\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[1;32m    734\u001b[0m     path_or_buf,\n\u001b[1;32m    735\u001b[0m     orient\u001b[39m=\u001b[39morient,\n\u001b[1;32m    736\u001b[0m     typ\u001b[39m=\u001b[39mtyp,\n\u001b[1;32m    737\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    738\u001b[0m     convert_axes\u001b[39m=\u001b[39mconvert_axes,\n\u001b[1;32m    739\u001b[0m     convert_dates\u001b[39m=\u001b[39mconvert_dates,\n\u001b[1;32m    740\u001b[0m     keep_default_dates\u001b[39m=\u001b[39mkeep_default_dates,\n\u001b[1;32m    741\u001b[0m     numpy\u001b[39m=\u001b[39mnumpy,\n\u001b[1;32m    742\u001b[0m     precise_float\u001b[39m=\u001b[39mprecise_float,\n\u001b[1;32m    743\u001b[0m     date_unit\u001b[39m=\u001b[39mdate_unit,\n\u001b[1;32m    744\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m    745\u001b[0m     lines\u001b[39m=\u001b[39mlines,\n\u001b[1;32m    746\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[1;32m    747\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[1;32m    748\u001b[0m     nrows\u001b[39m=\u001b[39mnrows,\n\u001b[1;32m    749\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m    750\u001b[0m     encoding_errors\u001b[39m=\u001b[39mencoding_errors,\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[1;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/anaconda3/envs/futebol/lib/python3.11/site-packages/pandas/io/json/_json.py:818\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlines:\n\u001b[1;32m    816\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnrows can only be passed if lines=True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 818\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m    819\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/futebol/lib/python3.11/site-packages/pandas/io/json/_json.py:874\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    866\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    867\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    868\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    869\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    873\u001b[0m ):\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File C:\\Users\\Galo\\Hugo_Personal\\Data\\Wyscout_Top_5\\matches\\matches_England.json does not exist"
     ]
    }
   ],
   "source": [
    "leagues = ['England', 'Spain']\n",
    "events = {}\n",
    "matches = {}\n",
    "minutes = {}\n",
    "for league in leagues:\n",
    "    path = f\"data/atv03/matches/matches_{league}.json\"\n",
    "    matches[league] = load_matches(path)\n",
    "    path = f\"data/atv03/events/events_{league}.json\"\n",
    "    events[league] = load_events(path)\n",
    "    path = r'C:\\Users\\Galo\\Hugo_Personal\\Data\\Wyscout_Top_5\\minutes_played\\minutes_played_per_game_{}.json'.format(league)  # criar isso aqui\n",
    "    minutes[league] = load_minutes_played_per_game(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"data/atv03/players/players.json\"\n",
    "players = load_players(path)\n",
    "players[\"player_name\"] = players[\"player_name\"].str.decode(\"unicode-escape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SPADL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import socceraction.spadl as spd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spadl_transform(events, matches):\n",
    "    spadl = []\n",
    "    game_ids = events.game_id.unique().tolist()\n",
    "    for g in tqdm(game_ids):\n",
    "        match_events = events.loc[events.game_id == g]\n",
    "        match_home_id = matches.loc[(matches.matchId == g) & (matches.side == 'home'), 'teamId'].values[0]\n",
    "        match_actions = spd.wyscout.convert_to_actions(events=match_events, home_team_id=match_home_id)\n",
    "        match_actions = spd.play_left_to_right(actions=match_actions, home_team_id=match_home_id)\n",
    "        match_actions = spd.add_names(match_actions)\n",
    "        spadl.append(match_actions)\n",
    "    spadl = pd.concat(spadl).reset_index(drop=True)\n",
    "\n",
    "    return spadl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [03:32<00:00,  1.78it/s]\n",
      "100%|██████████| 380/380 [03:27<00:00,  1.83it/s]\n",
      "100%|██████████| 306/306 [02:43<00:00,  1.87it/s]\n",
      "100%|██████████| 380/380 [03:32<00:00,  1.79it/s]\n",
      "100%|██████████| 380/380 [03:33<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "spadl = {}\n",
    "for league in leagues:\n",
    "    spadl[league] = spadl_transform(events=events[league], matches=matches[league])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from socceraction.vaep import features as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features_transform(spadl):\n",
    "    spadl.loc[spadl.result_id.isin([2, 3]), [\"result_id\"]] = 0\n",
    "    spadl.loc[spadl.result_name.isin([\"offside\", \"owngoal\"]), [\"result_name\"]] = \"fail\"\n",
    "\n",
    "    xfns = [\n",
    "        ft.actiontype_onehot,\n",
    "        ft.bodypart_onehot,\n",
    "        ft.result_onehot,\n",
    "        ft.goalscore,\n",
    "        ft.startlocation,\n",
    "        ft.endlocation,\n",
    "        ft.team,\n",
    "        ft.time,\n",
    "        ft.time_delta\n",
    "    ]\n",
    "\n",
    "    features = []\n",
    "    for game in tqdm(np.unique(spadl.game_id).tolist()):\n",
    "        match_actions = spadl.loc[spadl.game_id == game].reset_index(drop=True)\n",
    "        match_states = ft.gamestates(actions=match_actions)\n",
    "        match_feats = pd.concat([fn(match_states) for fn in xfns], axis=1)\n",
    "        features.append(match_feats)\n",
    "    features = pd.concat(features).reset_index(drop=True)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1- O que a primeira e a segunda linhas da função acima fazem? Qual sua hipótese sobre intuito dessas transformações? Como você acha que isso pode impactar o modelo final?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:08<00:00, 46.13it/s]\n",
      "100%|██████████| 380/380 [00:08<00:00, 44.44it/s]\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "for league in [\"England\", \"Spain\"]:\n",
    "    features[league] = features_transform(spadl[league])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socceraction.vaep.labels as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labels_transform(spadl):\n",
    "    yfns = [lab.scores, lab.concedes]\n",
    "\n",
    "    labels = []\n",
    "    for game in tqdm(np.unique(spadl.game_id).tolist()):\n",
    "        match_actions = spadl.loc[spadl.game_id == game].reset_index(drop=True)\n",
    "        labels.append(pd.concat([fn(actions=match_actions) for fn in yfns], axis=1))\n",
    "\n",
    "    labels = pd.concat(labels).reset_index(drop=True)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:09<00:00, 41.23it/s]\n",
      "100%|██████████| 380/380 [00:08<00:00, 42.32it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "for league in [\"England\", \"Spain\"]:\n",
    "    labels[league] = labels_transform(spadl[league])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7552"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"England\"][\"scores\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2314"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"England\"][\"concedes\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2- Explique o por que da quantidade de labels positivos do tipo scores ser muito maior que do concedes. Como você acha que isso pode impactar o modelo final?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import sklearn.metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_vaep(X_train, y_train, X_test, y_test):\n",
    "    models = {}\n",
    "    for m in [\"scores\", \"concedes\"]:\n",
    "        models[m] = xgb.XGBClassifier(random_state=0, n_estimators=50, max_depth=3)\n",
    "\n",
    "        print(\"training \" + m + \" model\")\n",
    "        models[m].fit(X_train, y_train[m])\n",
    "\n",
    "        p = sum(y_train[m]) / len(y_train[m])\n",
    "        base = [p] * len(y_train[m])\n",
    "        y_train_pred = models[m].predict_proba(X_train)[:, 1]\n",
    "        train_brier = mt.brier_score_loss(y_train[m], y_train_pred) / mt.brier_score_loss(y_train[m], base)\n",
    "        print(m + \" Train NBS: \" + str(train_brier))\n",
    "        print()\n",
    "\n",
    "        p = sum(y_test[m]) / len(y_test[m])\n",
    "        base = [p] * len(y_test[m])\n",
    "        y_test_pred = models[m].predict_proba(X_test)[:, 1]\n",
    "        test_brier = mt.brier_score_loss(y_test[m], y_test_pred) / mt.brier_score_loss(y_test[m], base)\n",
    "        print(m + \" Test NBS: \" + str(test_brier))\n",
    "        print()\n",
    "\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:18] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "scores Train NBS: 0.845201633845431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores Test NBS: 0.8505668629453046\n",
      "\n",
      "----------------------------------------\n",
      "training concedes model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:32] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "concedes Train NBS: 0.9655101118320947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concedes Test NBS: 0.9765081712829429\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = train_vaep(X_train=features[\"England\"], y_train=labels[\"England\"], X_test=features[\"Spain\"], y_test=labels[\"Spain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3- Por que treinamos dois modelos diferentes? Por que a performance dos dois é diferente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_predictions(features, models):\n",
    "    preds = {}\n",
    "    for m in [\"scores\", \"concedes\"]:\n",
    "        preds[m] = models[m].predict_proba(features)[:, 1]\n",
    "    preds = pd.DataFrame(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galo\\Anaconda3\\envs\\HP\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "preds[\"Spain\"] = generate_predictions(features=features[\"Spain\"], models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Action Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socceraction.vaep.formula as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_action_values(spadl, predictions):\n",
    "    action_values = fm.value(actions=spadl, Pscores=predictions['scores'], Pconcedes=predictions[\"concedes\"])\n",
    "    action_values = pd.concat([\n",
    "        spadl[[\"original_event_id\", \"action_id\", \"game_id\", \"start_x\", \"start_y\", \"end_x\", \"end_y\", \"type_name\", \"result_name\"]],\n",
    "        predictions.rename(columns={\"scores\": \"Pscores\", \"concedes\": \"Pconcedes\"}),\n",
    "        action_values\n",
    "    ], axis=1)\n",
    "\n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_values = {}\n",
    "action_values[\"Spain\"] = calculate_action_values(spadl=spadl[\"Spain\"], predictions=preds[\"Spain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4- Explore as ações com Pscores >= 0.95. Por que elas tem um valor tão alto? As compare com ações do mesmo tipo e resultado opostado. Será que o modelo aprende que essa combinação de tipo de ação e resultado está diretamente relacionado à variável y que estamos tentando prever?\n",
    "\n",
    "5- Qual formula do paper corresponde à coluna 'offensive_value' do dataframe action_values? E a coluna 'defensive_value'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Player Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_minutes_per_season(minutes_per_game):\n",
    "    minutes_per_season = minutes_per_game.groupby(\"player_id\", as_index=False)[\"minutes_played\"].sum()\n",
    "\n",
    "    return minutes_per_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minutes_per_season = {}\n",
    "minutes_per_season[\"Spain\"] = calculate_minutes_per_season(minutes[\"Spain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_player_ratings(action_values, minutes_per_season, players):\n",
    "    player_ratings = action_values.groupby(by=\"player_id\", as_index=False).agg({\"vaep_value\": \"sum\"}).rename(columns={\"vaep_value\": \"vaep_total\"})\n",
    "    player_ratings = player_ratings.merge(minutes_per_season, on=[\"player_id\"], how=\"left\")\n",
    "    player_ratings[\"vaep_p90\"] = player_ratings[\"vaep_total\"] / player_ratings[\"minutes_played\"] * 90\n",
    "    player_ratings = player_ratings[player_ratings[\"minutes_played\"] >= 600].sort_values(by=\"vaep_p90\", ascending=False).reset_index(drop=True)\n",
    "    player_ratings = player_ratings.merge(players, on=[\"player_id\"], how=\"left\")\n",
    "    player_ratings = player_ratings[[\"player_id\", \"player_name\", \"minutes_played\", \"vaep_total\", \"vaep_p90\"]]\n",
    "\n",
    "    return player_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_ratings = {}\n",
    "player_ratings[\"Spain\"] = calculate_player_ratings(action_values=action_values[\"Spain\"], minutes_per_season=minutes_per_season[\"Spain\"], players=players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6- Acha que o Top 5 da lista é bem representativo? Compare esse ranqueamento do VAEP com o do xT da Atividade 4. Qual você acha que é mais representativo?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
